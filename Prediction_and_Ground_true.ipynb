{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction_and_Ground_true.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3BoTzWwYKCNEvh8y8mrIc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryan840919/STAS-Detection/blob/main/Prediction_and_Ground_true.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1vPnuNNbUEK",
        "outputId": "a273b720-d925-4469-a230-971e2e3c43b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the images labeled by prediction result and ground true."
      ],
      "metadata": {
        "id": "OMLTJUMU1ef7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def P_G(test_name):\n",
        "  # make a file of the recent test_name to prepare to store the labeled images about to generate.\n",
        "  os.makedirs(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}')\n",
        "\n",
        "  filename = os.listdir(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels')\n",
        "  numlist = []\n",
        "  for fil in filename:\n",
        "    name = fil.split('.')\n",
        "    numlist.append(int(name[0]))\n",
        "\n",
        "  for num in numlist:\n",
        "    # open and read the labels.txt files generated by the recent test.\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels/{num:08}.txt','r') as R:\n",
        "      corlis = []\n",
        "      for line in R.readlines():\n",
        "        word = line.split(' ')\n",
        "        xmin = round(float(word[1])*1716-float(word[3])*1716/2)\n",
        "        ymin = round(float(word[2])*942-float(word[4])*942/2)\n",
        "        xmax = round(float(word[1])*1716+float(word[3])*1716/2)\n",
        "        ymax = round(float(word[2])*942+float(word[4])*942/2)\n",
        "        score = float(word[5])\n",
        "        cor = [xmin,ymax,xmax,ymin,score]\n",
        "        corlis.append(cor)\n",
        "\n",
        "    # open and read the labels.txt files that are initially given by the val set (ground true).\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/labels/val/{num:08}.txt','r') as RL:\n",
        "      corlisL = []\n",
        "      for line in RL.readlines():\n",
        "        wordL = line.split(' ')\n",
        "        xminL = round(float(wordL[1])*1716-float(wordL[3])*1716/2)\n",
        "        yminL = round(float(wordL[2])*942-float(wordL[4])*942/2)\n",
        "        xmaxL = round(float(wordL[1])*1716+float(wordL[3])*1716/2)\n",
        "        ymaxL = round(float(wordL[2])*942+float(wordL[4])*942/2)\n",
        "        corL = [xminL,ymaxL,xmaxL,yminL]\n",
        "        corlisL.append(corL)\n",
        "\n",
        "    # read the val image files that are initially splited\n",
        "    img = cv2.imread(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/images/val/{num:08}.jpg')\n",
        "    for cor in corlis:\n",
        "      cv2.rectangle(img, (cor[0],cor[1]), (cor[2],cor[3]),(0,0,255),2)\n",
        "      cv2.putText(img, f'{cor[4]}',(cor[0],cor[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
        "    for corL in corlisL:\n",
        "      cv2.rectangle(img, (corL[0],corL[1]), (corL[2],corL[3]),(0,255,0),2)\n",
        "    \n",
        "    # write the new labeled images that are generated by the recent test to the file.\n",
        "    cv2.imwrite(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}/{num:08}_labeled.jpg',img)"
      ],
      "metadata": {
        "id": "O3lkbGAObeBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_G('test_for_label')"
      ],
      "metadata": {
        "id": "61JoC-zYktqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_G('test_for_label_augmentation')"
      ],
      "metadata": {
        "id": "JRdZVEOyv-n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_G('test_with_background')"
      ],
      "metadata": {
        "id": "kQ21yC_JPWVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_G('test_with_background_lr0')"
      ],
      "metadata": {
        "id": "X1RGD23nKHmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the images that are prediction result but not ground true."
      ],
      "metadata": {
        "id": "odJr2x0X1njs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def P_not_G(test_name):  \n",
        "  os.makedirs(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_P_not_G')\n",
        "\n",
        "  filename = os.listdir(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels')\n",
        "  numlist = []\n",
        "  for fil in filename:\n",
        "    name = fil.split('.')\n",
        "    numlist.append(int(name[0]))\n",
        "\n",
        "  for n in numlist:\n",
        "    im = cv2.imread(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/images/val/{n:08}.jpg')\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/labels/val/{n:08}.txt','r') as RL:\n",
        "      corlisL = []\n",
        "      for line in RL.readlines():\n",
        "        wordL = line.split(' ')\n",
        "        xminL = round(float(wordL[1])*1716-float(wordL[3])*1716/2)\n",
        "        yminL = round(float(wordL[2])*942-float(wordL[4])*942/2)\n",
        "        xmaxL = round(float(wordL[1])*1716+float(wordL[3])*1716/2)\n",
        "        ymaxL = round(float(wordL[2])*942+float(wordL[4])*942/2)\n",
        "        corL = [xminL,ymaxL,xmaxL,yminL]\n",
        "        corlisL.append(corL)\n",
        "\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels/{n:08}.txt','r') as R:\n",
        "      corlis = []\n",
        "      for line in R.readlines():\n",
        "        word = line.split(' ')\n",
        "        xcen = round(float(word[1])*1716)\n",
        "        ycen = round(float(word[2])*942)\n",
        "        xminL = round(float(word[1])*1716-float(word[3])*1716/2)\n",
        "        yminL = round(float(word[2])*942-float(word[4])*942/2)\n",
        "        xmaxL = round(float(word[1])*1716+float(word[3])*1716/2)\n",
        "        ymaxL = round(float(word[2])*942+float(word[4])*942/2)\n",
        "        score = float(word[5])\n",
        "        cor = [xcen,ycen,xminL,ymaxL,xmaxL,yminL,score]\n",
        "        corlis.append(cor)\n",
        "\n",
        "    count = 0\n",
        "    for cor in corlis:\n",
        "      if not any(corL[0]<=cor[0]<=corL[2] and corL[3]<=cor[1]<=corL[1] for corL in corlisL):\n",
        "        count += 1\n",
        "        pim = im[cor[5]:cor[3],cor[2]:cor[4]]\n",
        "        cv2.imwrite(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_P_not_G/{n:08}_{count}.jpg',pim)\n",
        "        with open(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_P_not_G/{n:08}_{count}.txt','w') as S:\n",
        "          S.write(f'{cor[6]}')"
      ],
      "metadata": {
        "id": "VnIu9bRVZYKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G('test_for_label')"
      ],
      "metadata": {
        "id": "hiE1k0YpfzdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G('test_for_label_augmentation')"
      ],
      "metadata": {
        "id": "VSf6FPr-wyWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G('test_with_background')"
      ],
      "metadata": {
        "id": "75qI0UtiPyjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G('test_with_background_lr0')"
      ],
      "metadata": {
        "id": "myiMx50PKNRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the images that are ground true but not be predicted."
      ],
      "metadata": {
        "id": "iVtHdI4h1vjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def G_not_P(test_name):  \n",
        "  os.makedirs(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_G_not_P')\n",
        "\n",
        "  filename = os.listdir(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels')\n",
        "  numlist = []\n",
        "  for fil in filename:\n",
        "    name = fil.split('.')\n",
        "    numlist.append(int(name[0]))\n",
        "\n",
        "  for n in numlist:\n",
        "    im = cv2.imread(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/images/val/{n:08}.jpg')\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/labels/val/{n:08}.txt','r') as RL:\n",
        "      corlisL = []\n",
        "      for line in RL.readlines():\n",
        "        wordL = line.split(' ')\n",
        "        xcenL = round(float(wordL[1])*1716)\n",
        "        ycenL = round(float(wordL[2])*942)\n",
        "        xminL = round(float(wordL[1])*1716-float(wordL[3])*1716/2)\n",
        "        yminL = round(float(wordL[2])*942-float(wordL[4])*942/2)\n",
        "        xmaxL = round(float(wordL[1])*1716+float(wordL[3])*1716/2)\n",
        "        ymaxL = round(float(wordL[2])*942+float(wordL[4])*942/2)\n",
        "        corL = [xcenL,ycenL,xminL,ymaxL,xmaxL,yminL]\n",
        "        corlisL.append(corL)\n",
        "\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels/{n:08}.txt','r') as R:\n",
        "      corlis = []\n",
        "      for line in R.readlines():\n",
        "        word = line.split(' ')\n",
        "        xminL = round(float(word[1])*1716-float(word[3])*1716/2)\n",
        "        yminL = round(float(word[2])*942-float(word[4])*942/2)\n",
        "        xmaxL = round(float(word[1])*1716+float(word[3])*1716/2)\n",
        "        ymaxL = round(float(word[2])*942+float(word[4])*942/2)\n",
        "        cor = [xminL,ymaxL,xmaxL,yminL]\n",
        "        corlis.append(cor)\n",
        "\n",
        "    count = 0\n",
        "    for corL in corlisL:\n",
        "      if not any(cor[0]<=corL[0]<=cor[2] and cor[3]<=corL[1]<=cor[1] for cor in corlis):\n",
        "        count += 1\n",
        "        pim = im[corL[5]:corL[3],corL[2]:corL[4]]\n",
        "        cv2.imwrite(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_G_not_P/{n:08}_{count}.jpg',pim)"
      ],
      "metadata": {
        "id": "CKGyBuNaA0g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_not_P('test_for_label')"
      ],
      "metadata": {
        "id": "2lJvtfxOC-yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_not_P('test_for_label_augmentation')"
      ],
      "metadata": {
        "id": "VkD3eWixw6jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_not_P('test_with_background')"
      ],
      "metadata": {
        "id": "1elkKNdiQTiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_not_P('test_with_background_lr0')"
      ],
      "metadata": {
        "id": "-ltdx67vKTLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate bigger region for false-positive."
      ],
      "metadata": {
        "id": "nsIdP48YrXAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def P_not_G_bigger(test_name):  \n",
        "  os.makedirs(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_P_not_G_bigger')\n",
        "\n",
        "  filename = os.listdir(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels')\n",
        "  numlist = []\n",
        "  for fil in filename:\n",
        "    name = fil.split('.')\n",
        "    numlist.append(int(name[0]))\n",
        "\n",
        "  for n in numlist:\n",
        "    im = cv2.imread(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/images/val/{n:08}.jpg')\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/data/STAS_YOLOv5_PS/labels/val/{n:08}.txt','r') as RL:\n",
        "      corlisL = []\n",
        "      for line in RL.readlines():\n",
        "        wordL = line.split(' ')\n",
        "        xminL = round(float(wordL[1])*1716-float(wordL[3])*1716/2)\n",
        "        yminL = round(float(wordL[2])*942-float(wordL[4])*942/2)\n",
        "        xmaxL = round(float(wordL[1])*1716+float(wordL[3])*1716/2)\n",
        "        ymaxL = round(float(wordL[2])*942+float(wordL[4])*942/2)\n",
        "        corL = [xminL,ymaxL,xmaxL,yminL]\n",
        "        corlisL.append(corL)\n",
        "\n",
        "    with open(f'/content/gdrive/MyDrive/AI競賽_運算/yolov5/yolov5/runs/val/{test_name}/labels/{n:08}.txt','r') as R:\n",
        "      corlis = []\n",
        "      for line in R.readlines():\n",
        "        word = line.split(' ')\n",
        "        xcen = round(float(word[1])*1716)\n",
        "        ycen = round(float(word[2])*942)\n",
        "        xminL = round(float(word[1])*1716-float(word[3])*1716/2)\n",
        "        yminL = round(float(word[2])*942-float(word[4])*942/2)\n",
        "        xmaxL = round(float(word[1])*1716+float(word[3])*1716/2)\n",
        "        ymaxL = round(float(word[2])*942+float(word[4])*942/2)\n",
        "        score = float(word[5])\n",
        "        cor = [xcen,ycen,xminL,ymaxL,xmaxL,yminL,score]\n",
        "        corlis.append(cor)\n",
        "\n",
        "    count = 0\n",
        "    for cor in corlis:\n",
        "      if not any(corL[0]<=cor[0]<=corL[2] and corL[3]<=cor[1]<=corL[1] for corL in corlisL):\n",
        "        count += 1\n",
        "        pim = im[max(cor[5]-10,0):min(cor[3]+10,942),max(cor[2]-10,0):min(cor[4]+10,1716)]\n",
        "        cv2.imwrite(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_P_not_G_bigger/{n:08}_{count}.jpg',pim)\n",
        "        # with open(f'/content/gdrive/MyDrive/AI競賽_運算/data/val_labeled/{test_name}_P_not_G_bigger/{n:08}_{count}.txt','w') as S:\n",
        "        #   S.write(f'{cor[6]}')"
      ],
      "metadata": {
        "id": "0B9PDqCHfz9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G_bigger('test_for_label')"
      ],
      "metadata": {
        "id": "bK2U9g3bgVqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G_bigger('test_for_label_augmentation')"
      ],
      "metadata": {
        "id": "Fzek5aGuiz7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G_bigger('test_with_background')"
      ],
      "metadata": {
        "id": "kp7F8RaDRDE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_not_G_bigger('test_with_background_lr0')"
      ],
      "metadata": {
        "id": "dtkT2Fd8KpsZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}